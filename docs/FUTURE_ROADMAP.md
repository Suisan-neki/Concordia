# ゼロプレッシャー合意 実装ロードマップ

## 現状の整理

### ✅ すでに実装済み
- 理解行動の記録（Understanding Events）
- Merkle Chain による改ざん検知
- LLM による理解度評価
- 署名・不可否認性
- Telemetry (Calm/Observe/Focus)

### ❌ まだ実装されていない
- **合意形成の支援機能**
- **合意を促進するUX**
- **合意過程の透明性**

---

## ロードマップ

### Phase 1: 小さな実装（1-2週間）

#### 1.1 感情・理解度の自然な検出
```
【実装内容】
- リアクションボタンは使わない（プレッシャーになるため）
- LLM が会話の文脈から感情・理解度を自動検出
- 「もっと詳しく」と言われたときに「質問」として記録
- 「なるほど」と言われたときに「理解した」として記録
- 明示的なボタンは最小限に、会話の流れを妨げない

【社会的価値】
- 「場の空気を読む」圧力からの解放
- 自然な対話を維持しながら理解度を記録
- 合意の質を向上
```

#### 1.2 合意状況の可視化（オプトイン）
```
【実装内容】
- セッション終了後、任意で合意状況を確認可能に
- 「合意できた点」「まだ確認が必要な点」を提示
- 見たい人だけが見る、見ない人には見せない

【社会的価値】
- 合意の進捗を透明に
- プレッシャーを感じさせない合意形成
```

#### 1.3 LLM による合意ポイント抽出
```
【実装内容】
- セッション終了時に LLM が自動的に合意できた点を抽出
- 「合意できたこと / まだ曖昧なこと」を整理して提示

【社会的価値】
- 表面的な合意を防ぐ
- 次回への橋渡し
```

---

### Phase 2: 中規模実装（1-2ヶ月）

#### 2.1 質問候補の自動生成
```
【実装内容】
- LLM が会話の文脈から「聞けば良かった質問」を生成
- セッション中、話し手側に「もしかしてここで質問があれば...」と優しく促す
- 質問するかどうかは聞き手の判断
- 質問がなくても問題なし、強制しない

【社会的価値】
- 質問を忘れる不安の軽減
- より深い理解を促進
- 医師も「どこが分かりにくいか」を事前に把握
```

#### 2.2 合意可能な点の自動分解
```
【実装内容】
- 大きな合意を小さな合意に分解
- 例：「手術に合意」→「手術の必要性」「麻酔方法」「術後経過」など
- 一つずつ段階的に合意を形成

【社会的価値】
- 全か無かの合意を避ける
- 不安を最小化
- 柔軟な合意形成
```

#### 2.3 対話ログの要約・文脈共有
```
【実装内容】
- セッション終了時に LLM が対話を要約
- 次回のセッションで「前回はここまで合意できている」を表示
- 継続的な合意形成をサポート

【社会的価値】
- 合意がリセットされない
- 継続的な信頼関係の構築
- 時間をかけた合意形成が可能に
```

---

### Phase 3: 大規模実装（3-6ヶ月）

#### 3.1 複数ステークホルダーへの対応
```
【実装内容】
- 患者・家族・医師・看護師など複数人の合意形成
- それぞれの立場からの質問・確認を記録
- 全体の合意状況を可視化

【社会的価値】
- 家族間の意見の相違を可視化
- 医療チーム全体の合意形成
- より民主的な医療判断
```

#### 3.2 合意過程のアーカイブ・検証
```
【実装内容】
- 合意に至るまでのプロセス全体をアーカイブ
- 第三者（監査者・法廷）が合意の妥当性を検証可能に
- 圧力や誘導の痕跡を技術的に検出

【社会的価値】
- 医療訴訟の予防
- 透明性の向上
- 医療従事者の保護
```

#### 3.3 組織・コミュニティの合意形成
```
【実装内容】
- 病院全体での合意形成プロセスの可視化
- 組織の合意形成の質を評価
- 部署間の意見交換を記録

【社会的価値】
- 組織の民主化
- 多様な意見の尊重
- 合意形成の文化を変える
```

---

## 社会的インパクトの定義

### なぜ「合意を記録する」だけでは不十分か
- 単なる記録は「合意を押し付けた証拠」になり得る
- 記録するだけでは、合意の質は向上しない
- プレッシャーを感じさせない「合意の支援」が必要

### ゼロプレッシャー合意が目指すもの
1. **表面的な合意を防ぐ**  
   - 黙諾ではない真の合意を実現
   - 質問や不安を隠さない環境づくり

2. **合意のプロセスを透明にする**  
   - 圧力や誘導の痕跡を技術的に検証可能に
   - 第三者も合意の妥当性を確認できる

3. **社会全体の合意形成文化を変える**  
   - 医療だけでなく、組織・コミュニティへ展開
   - 合意形成の新しいモデルを提示

---

## 次のステップ

### すぐに始められること
1. **Phase 1 の実装**  
   - LLM による理解度の自然な検出のプロトタイプ
   - CLI で動作確認
   - Docker 環境でテスト

2. **ユーザーインタビュー**  
   - 医療現場で実際に使う人にヒアリング
   - どの機能が最も必要か確認
   - 改善点を洗い出す

3. **小さな実験から始める**  
   - 1-2のセッションで試用
   - フィードバックを収集
   - 改善して再度試用

### 長期的なビジョン
- **医療以外の領域への展開**  
  - 教育（生徒・保護者・教師の合意形成）
  - 企業（経営者・従業員・労働組合）
  - 地域（住民・行政・事業者）

- **社会的な制度との連携**  
  - 医療法・労働法との整合性
   - 司法制度との連携
   - 国際的な標準化

---

## まとめ

ゼロプレッシャー合意の実装は、「記録する」から「支援する」へと進化させることが重要である。

小さな実装から始め、段階的に機能を拡張することで、  
**社会全体の合意形成文化を変える**ことができる。

既存の LLM 評価機能を活かし、  
**合意の質**を向上させながら、  
**プレッシャーを感じさせない合意形成**を実現していく。

---

## 実装の課題と対処法

### 課題1: LLM の凡庸性
**問題点:**
- 汎用 LLM に会話を渡すだけでは「一般的な評価」しか得られない
- 医療現場の専門性・文脈を理解できない
- 「何でも良い」という均質な回答になりがち

**対処法:**
1. **プロンプトエンジニアリング**
   - 医療現場の文脈を明示的に指定
   - ゼロプレッシャー合意の原則をプロンプトに組み込む
   - 具体例をプロンプトに含める

2. **Few-shot Learning**
   - 実際の良い対話例をプロンプトに含める
   - 評価基準を明確に定義

3. **Fine-tuning の検討**
   - 医療現場のデータで Fine-tuning
   - ただしコストとデータ収集の課題あり

### 課題2: セキュリティとプライバシー
**問題点:**
- 医療情報を外部 LLM に送信するのは GDPR/HIPAA 違反の可能性
- データが外部に漏洩するリスク
- 患者の同意が必要

**対処法:**
1. **ローカル LLM の利用**
   - GPT-4 の代替として Claude / Llama を検討
   - 病院内サーバーで完結

2. **データ匿名化**
   - 医療情報をマスキングしてから LLM に送信
   - しかし匿名化が不完全だとリスク

3. **オンプレミス LLM API**
   - Google Cloud / Azure のオンプレミス LLM API
   - ただしコストが高い

### 課題3: コスト
**問題点:**
- GPT-4 は 1 セッションあたり数百円かかる可能性
   - トークン量: 会話ログ（数千トークン）× 評価プロンプト = 10k トークン以上
   - 料金: $0.03/1k tokens (入力) + $0.06/1k tokens (出力) = $0.09/1k tokens
   - 1 セッション = 10k tokens × $0.09 = $0.9 = 約 130 円
- Gemini Flash は安いが品質が不安定（すでに経験済み）

**対処法:**
1. **評価の頻度を下げる**
   - 全セッションではなく、数%のサンプルだけ評価
   - 必要時にのみ LLM 評価を実行

2. **バッチ処理**
   - 日中はデータ収集のみ、夜間にバッチで LLM 評価

3. **軽量 LLM の活用**
   - Llama 3 などをローカルで実行
   - ただし品質は GPT-4 より劣る可能性

### 課題4: 実用的な代替案
**「LLM なしでも価値を提供する」機能:**

1. **パターンマッチングによる自動分類**
   ```
   - 「わからない」「もっと詳しく」→ CLARIFY
   - 「なるほど」「分かりました」→ AGREE
   - 「ちょっと待って」→ PENDING
   ```
   これなら LLM 不要で低コスト

2. **テンプレートベースの評価**
   ```
   - セッション中の「質問の数」で評価
   - 「再確認の回数」で評価
   - LLM ではなく統計で判定
   ```

3. **人間の評価と組み合わせる**
   ```
   - LLM は初期フィルタリングのみ
   - 最終判断は人間が行う
   - コストを下げつつ品質を保つ
   ```

### 推奨される実装アプローチ
1. **Phase 1: LLM なしで実装**
   - パターンマッチングで理解度を自動検出
   - コストゼロで MVP を作成

2. **Phase 2: オプション機能として LLM を追加**
   - LLM 評価は「有料オプション」として提供
   - 必要に応じて手動で実行

3. **Phase 3: ローカル LLM を検討**
   - コストとセキュリティのバランスを取る
   - オンプレミス LLM API を活用

---

## まとめ（修正版）

ゼロプレッシャー合意の実装は、**LLM に依存しすぎない**ことが重要。

- **Phase 1: パターンマッチングで理解度を検出**
  - LLM なしでも価値を提供
  - コストゼロ、セキュリティリスクゼロ
  
- **Phase 2: LLM 評価をオプションとして追加**
  - 必要に応じて手動実行
  - コストは利用者負担

- **Phase 3: ローカル LLM で統合**
  - コストとセキュリティのバランス
  - オンプレミス環境での展開

小さな実装から始め、**LLM の課題を回避しながら**  
**プレッシャーを感じさせない合意形成**を実現していく。
